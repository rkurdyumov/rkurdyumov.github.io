<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
    <link rel="stylesheet" href="main_style.css">
    <title>Sign Language Recognition</title>
  </head>
  <body>
    <div id="nav-placeholder"></div>

    <main class="container limit-width p-3 mx-0 ">
      <h2>Sign Language Recognition</h2>
      <p>For the Stanford CS229 Machine Learning final project, I worked on sign language
        recognition.  The motivation was that immediate feedback on sign language gestures
        can greatly improve sign language education.

      <div class="row">
        <div class="col-sm">
          <figure class="figure">
            <img src="uploads/sign_language_dataset.png" class="figure-img img-fluid" alt="Sign language dataset">
            <figcaption class="figure-caption">Sign language dataset.</figcaption>
          </figure>
        </div>
        <div class="col-sm">
          <p>The dataset consisted of 1800 self-produced webcam images of 3 people
            signing 25 American sign language alphabet signs.
        </div>
      </div>

      <div class="row">
        <div class="col-sm">
          <figure class="figure">
            <img src="uploads/sign_language_processing.png" class="figure-img img-fluid" alt="Image processing workflow">
            <figcaption class="figure-caption">Image processing workflow.</figcaption>
          </figure>
        </div>
        <div class="col-sm">
          <p>We normalize and scale the images to 20 x 20px, and use the binary pixels
            as features.  See the figure for the image processing workflow, which includes
            background subtraction (b), binarizing (c), image cleanup (d,e) and normalizing (f,g).
        </div>
      </div>

      <p>We can successfully classify up to 93% of the signs using a linear or
        Gaussian kernel SVM, outperforming k-nearest neighbor classification by
        about 10%. Using a custom set of features we developed, we can successfully
        classify 81% of the signs with an SVM.

      <p>For more detail, see the <a href="uploads/sign_language_webcam_paper.pdf">final paper</a>.
    </main>

    <script src="https://code.jquery.com/jquery-3.5.1.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
    <script src="load_placeholders.js"></script>
  </body>
</html>